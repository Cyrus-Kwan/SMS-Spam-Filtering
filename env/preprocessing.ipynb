{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "# Agenda\n",
    "1. Identify the tokens/rules that will be used to split the content into words\n",
    "2. Convert SMS content into word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_df = pd.read_csv(\n",
    "    filepath_or_buffer=\"./spam.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>True</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>False</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>False</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>False</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>False</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Spam                                               Text\n",
       "0     False  Go until jurong point, crazy.. Available only ...\n",
       "1     False                      Ok lar... Joking wif u oni...\n",
       "2      True  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3     False  U dun say so early hor... U c already then say...\n",
       "4     False  Nah I don't think he goes to usf, he lives aro...\n",
       "...     ...                                                ...\n",
       "5569   True  This is the 2nd time we have tried 2 contact u...\n",
       "5570  False               Will ü b going to esplanade fr home?\n",
       "5571  False  Pity, * was in mood for that. So...any other s...\n",
       "5572  False  The guy did some bitching but I acted like i'd...\n",
       "5573  False                         Rofl. Its true to its name\n",
       "\n",
       "[5574 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens\n",
    "From: Almeida, T. A., Hidalgo, J. M. G., & Yamakami, A. (2011, September). Contributions to the study of SMS spam filtering: new collection and results. In Proceedings of the 11th ACM symposium on Document engineering (pp. 259-262).\n",
    "1. tokens start with a printable character, followed by any number of alphanumeric characters, excluding dots, commas and colons  from the middle of the pattern.\n",
    "2. any sequence of characters separated by blanks, tabs, returns, dots, commas, colons and dashes are considered as tokens.\n",
    "\n",
    "### Criticism\n",
    "The tokens described in the paper do not adequately capture the words for this data as some uncecessary punctuation is included.\n",
    "\n",
    "**Example:**\n",
    "> ``` Python\n",
    "> # Example sentences\n",
    "> \"I was under-prepared.\"\n",
    "> \"I was under-prepared?\"\n",
    "> \"I was under-prepared!\"\n",
    "> \n",
    "> tok1 = \"I\", \"was\", \"under-prepared\"\n",
    "> tok1 = \"I\", \"was\", \"under-prepared?\"\n",
    "> tok1 = \"I\", \"was\", \"under-prepared!\"\n",
    "> \n",
    "> tok2 = \"I\", \"was\", \"under\", \"prepared\"\n",
    "> tok2 = \"I\", \"was\", \"under\", \"prepared?\"\n",
    "> tok2 = \"I\", \"was\", \"under\", \"prepared!\"\n",
    "> ```\n",
    "\n",
    "**Expectation:**\n",
    "> ``` Python\n",
    "> \"I was under-prepared.\"\n",
    "> \"I was under-prepared?\"\n",
    "> \"I was under-prepared!\"\n",
    ">\n",
    "> tok = \"I\", \"was\", \"under\", \"prepared\"\n",
    "> tok = \"I\", \"was\", \"under\", \"prepared\"\n",
    "> tok = \"I\", \"was\", \"under\", \"prepared\"\n",
    "> ```\n",
    "\n",
    "### Solution\n",
    "[Regular expression solution from sklearn library](https://github.com/scikit-learn/scikit-learn/blob/d5082d32d/sklearn/feature_extraction/text.py#L350): `(?u)\\b\\w\\w+\\b`\n",
    "\n",
    "This method converts all sentences in the corpus to lower case and only retrieves alphanumeric characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return matrix of tfidf score for each configuration of documents (rows) and words (columns)\n",
    "vectorizer = TfidfVectorizer()\n",
    "spam_sparse = vectorizer.fit_transform(spam_df[\"Text\"])\n",
    "spam_dense = spam_sparse.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_vec = pd.DataFrame(\n",
    "    spam_dense, columns=feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_vec.to_csv(\n",
    "    path_or_buf=\"spam_vec.csv\", index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
